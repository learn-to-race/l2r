# parameters for the baseline RandomActionAgent

il_kwargs:
  learning_rate: 0.0002 
  seed: 0
  total_steps: 2_000_000
  replay_size: 100_000
  batch_size: 256
  start_steps: 1000
  update_after: 3000
  num_updates: 5
  num_episodes: 10
  max_ep_len: 5000
  encoder_path: './baselines/models/vae-144hw-32l-lvms.pt'
  latent_dims: 32
  im_w: 144
  im_h: 144
  checkpoint: './baselines/checkpoints/lvms/il_episode_1000.pt'
  inference_only: True
  save_path: './results/il/'
  TRAIN_BS: 64
  VAL_BS: 128
  CPU: 8
  GPU: 1
  PIN: TRUE
  DATASET:
      LOCATION: "/home/bingqinc/l2r_expert_demonstrations"
      NAME: "thruxton"
      SPLIT:
          TRAIN: "train"
          VAL: "val"

env_kwargs:
  multimodal: True
  max_timesteps: 500
  obs_delay: 0.1
  not_moving_timeout: 50
  reward_pol: 'default'
  reward_kwargs:
    oob_penalty: 5.0
    min_oob_penalty: 25.0
  controller_kwargs:
    sim_version: 'ArrivalSim-linux-0.3.0.137341-roborace'
    quiet: False
    start_container: True
  action_if_kwargs:
    max_accel: 6.
    min_accel: 3.
    max_steer: 0.2
    min_steer: -0.2
    ip: '0.0.0.0'
    port: 7077
  pose_if_kwargs:
    ip: '0.0.0.0'
    port: 7078
  camera_if_kwargs:
    ip: 'tcp://127.0.0.1'
    port: 8008
  logger_kwargs:
    default: True

sim_kwargs:
  racetrack: 'VegasNorthRoad' # ['VegasNorthRoad', 'Thruxton']
  active_sensors:
    - ImuOxtsSensor
    - CameraFrontRGB
  driver_params:
    DriverAPIClass: 'VApiUdp'
    DriverAPI_UDP_SendAddress: '0.0.0.0'
  camera_params:
    Format: ColorBGR8
    FOVAngle: 90
    Width: 512
    Height: 384
    bAutoAdvertise: True

# From https://github.com/felipecode/coiltraine/blob/master/configs/sample/coil_icra.yaml
MODEL_CONFIGURATION:  # Based on the MODEL_TYPE, we specify the structure
  perception:  # The module that process the image input, it ouput the number of classes
    conv:
      channels: [32, 32, 64, 64, 128, 128, 256, 256]
      kernels: [5, 3, 3, 3, 3, 3, 3, 3]
      strides: [2, 1, 2, 1, 2, 1, 1, 1]
      dropouts: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
    fc:
      neurons: [512, 512]
      dropouts: [0.5, 0.5]
  measurements:  # The module the process the input float data, in this case speed_input
    fc:  # Easy to configure fully connected layer
      neurons: [128, 128] # Each position add a new layer with the specified number of neurons
      dropouts: [0.0, 0.0]
  join:  # The module that joins both the measurements and the perception
    fc:
      neurons: [512]
      dropouts: [0.0]
  speed_branch:  # The prediction branch speed branch
    fc:
      neurons: [256, 256]
      dropouts: [0.0, 0.5]
  branches:  # The output branches for the different possible directions ( Straight, Left, Right, None)
    number_of_branches: 1#4
    fc:
      neurons: [256, 256]
      dropouts: [0.0, 0.5]
